---
layout: post
title: meecord
tags: [Firebase, Python, PyTorch, WebRTC]
excerpt_separator: <!--more-->
---

# Meecord

<!--more-->

감정분석을 토대로한 비대면 소개팅 서비스입니다. <br>
'Meecord'는 비대면 1:1로 진행되는 미팅에서 표정인식과 음성인식을 통해 감정을 분석하고 실시간 TIP을 제공합니다.

---

## 🔗 Github

- **Github Repository**  
  [![Github](https://img.shields.io/badge/Github-Repository-black?logo=github)](https://github.com/pantokr/meecord)

- **Git Clone**  
  ```bash
  git clone https://github.com/pantokr/meecord.git
  ```

---

## 🟢 구조도

<img src="/assets/img/posts/2022-06-17-meecord/process.png" alt="구조도" style="width:100%;">

## 📌 주요 기능

### 1. 방 생성, 방 참가
- 미팅룸을 생성하거나 생성된 미팅룸에 입장할 수 있습니다. 
- 동일한 코드의 미팅룸에 두 명이 입장 시 자동으로 STT, 감정분석 등이 실행됩니다.

### 2. 대화록 작성
- **speach recognition API**를 통해 상대방과의 대화 내용이 우측 하단 대화록에 업데이트됩니다. 
- 작성된 대화 내용은 실시간으로 데이터베이스에 저장이 되며, 이는 대화 종료 후 대화목록에 가서 해당 대화를 선택하면 다시 확인할 수 있습니다. 
- 동일한 코드의 미팅룸에 두 명이 입장 시 자동으로 STT, 감정분석 등이 실행됩니다.
  
### 3. 감정 분석
- **음성 감정분석 모델**과 **표정 감정분석 API**를 통해 상대방의 감정을 분석합니다. 
- 상대방의 발언 시에는 음성인식 API를, 발언 중이 아니라면 표정 감정분석 API를 이용합니다. 
- 분석된 데이터를 4가지 감정으로 분류하여 사용자의 화면에 띄우고, TIP에 사용하며, 데이터베이스에 저장합니다. 
- 소개팅 기록에서는 데이터베이스에서 감정 정보를 불러와 해당 소개팅에서의 감정에 대한 분포도 및 어떤 키워드에 어떤 감정이 드러났는지를 알 수 있습니다. 

### 4. TIP 제공
- 어떤 말을 해야할 지 모르겠을 때 필요한 무작위 질문 TIP, 상대방의 급격한 감정 변화나 변화지 않는 감정 상태에 따른 TIP, 상대방의 현재 대화 및 과거 대화 기록을 분석한 TIP을 제공합니다. 
- TIP들은 실시간의 상대방의 감정 및 키워드 뿐만 아니라 상대방의 이전의 소개팅에서 나타났던 감정과 키워드를 기반으로 합니다.

### 5. 대화목록
- 해당 소개팅 방에서의 대화 내용 및 감정의 분포, 그리고 4가지 감정별 최빈 키워드를 제공합니다. 
- 이전 대화 중에 실시간으로 저장된 감정 및 키워드를 사용해 분석 결과를 제공합니다. 

---

## 📆 제작 과정

<img src="/assets/img/posts/2022-06-17-meecord/list.png" alt="제작 과정" style="width:100%;">

---

## ✏️ 담당 분야

- 음성 감정분석 모델 개발
- API 서버 구축
- 데이터베이스 설계 및 구축
- 키워드 응용 관련 기능적 함수 개발

---

## 📚 이론 및 기술

### 음성 감정인식 모델

#### 수학, 기초과학
- **Fourier Transform (FFT)**: MFCC를 만들기 위한 음성 데이터 분해식
- **Standardization**: MFCC가 적용된 음성 데이터 값 범위 축소에 사용된 스케일링 방식
- **Cross Entropy**: 머신러닝 손실함수
- **Adam**: 머신러닝 최적화 함수
- **ReLU**: 활성화 함수

#### 정보기술
- **MFCC**: 음성 데이터 특징 추출 및 전처리
- **CNN**: Conv2d, Batch, Norm2d, ReLU, MaxPool2d, Dropout, Linear등의 과정을 거친 합성곱 신경망

---

## 시험 결과

### 음성 감정인식 테스트 결과

<img src="/assets/img/posts/2022-06-17-meecord/test.png" alt="테스트 화면" style="width:100%;">
_음성 데이터 200개 중 148개가 실제 감정으로 일치_

---

## 📸 스크린샷

**1. 메인 화면**

<img src="/assets/img/posts/2022-06-17-meecord/main.png" alt="메인 화면" style="width:100%;">

<img src="/assets/img/posts/2022-06-17-meecord/menu.png" alt="메뉴 화면" style="width:100%;">

<img src="/assets/img/posts/2022-06-17-meecord/private.png" alt="동의서 화면" style="width:100%;">
  
<br>

**2. 미팅 화면**

<img src="/assets/img/posts/2022-06-17-meecord/meeting.png" alt="미팅 화면" style="width:100%;">

<br>

**3. 결과 화면**

<img src="/assets/img/posts/2022-06-17-meecord/list.png" alt="미팅 화면" style="width:100%;">

<img src="/assets/img/posts/2022-06-17-meecord/mypage.png" alt="결과 화면" style="width:100%;">


---

## 🛠️ 개발환경

- **기술 스택**: Firebase, Python, PyTorch, WebRTC
- **지원 OS**: Chrome

---

## 참고 문헌
- [**"CNN – LSTM 모델 기반 음성 감정인식"**](https://www.koreascience.or.kr/article/CFKO202133648871932.pdf) 
- [**"음성 신호를 이용한 감정인식기술의 연구동향분석"**]
(https://manuscriptlink-society-file.s3-ap-northeast-1.amazonaws.com/sma/conference/sma2020fall/presentation/51.pdf)

---

## 📋 기타
- **화상인식 API**: [face-api.js](https://github.com/justadudewhohacks/face-api.js)
- **개체명인식 API**: [ETRI NER](https://aiopen.etri.re.kr/)